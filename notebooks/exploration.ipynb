{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a38c3145-08df-4c98-8ee1-aafc799e7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from functools import partial\n",
    "import string\n",
    "import bitsandbytes\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c72650-c568-40a1-aea5-7e2240a5a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"REDACTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d9a06e-3bd8-442c-bbf5-eea39ecbbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6056570-a450-4f52-8a46-c992280524ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.29s/it]\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B'\n",
    "# model = HookedTransformer.from_pretrained_no_processing(model_name, device=device, dtype='float16')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab54636b-5cc5-4018-8544-e330ce149a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b1af05-f1e4-49cf-b97b-42cac36bd6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "release = \"llama_scope_r1_distill\"\n",
    "sae_id = \"l25r_400m_slimpajama_400m_openr1_math\"\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained_with_cfg_and_sparsity(release, sae_id)\n",
    "sae = sae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97374fe5-16af-4809-b7e8-32852c01c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_aqua(query, reasoning=True):\n",
    "    question, options = query['question'], query['options']\n",
    "    joined_options = \"\\n\".join(options)\n",
    "    COT_PROMPT = r'Please reason step by step, and put your final answer within \\boxed{}.'\n",
    "    if reasoning:\n",
    "        return f'<s>[INST] {question}\\n{COT_PROMPT} [/INST] \\n<think>\\n'\n",
    "    else:\n",
    "        return f'<s>[INST] {question}\\n [/INST] \\n'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "429e7732-5859-40fd-80d3-9f8c97d24448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_tqa(question, reasoning=True):\n",
    "    COT_PROMPT = r'Please reason step by step, and put your final answer within \\boxed{}.'\n",
    "    if reasoning:\n",
    "        return f'<s>[INST] {question}\\n{COT_PROMPT} [/INST] \\n<think>\\n'\n",
    "    else:\n",
    "        return f'<s>[INST] {question}\\n [/INST] \\n'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1438d6-d410-43ce-80d5-f096ede15557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cot(model, tokenizer, query):\n",
    "    \"\"\"\n",
    "    Function to get the response from a model to an MCQ - both the prediction and the reasoning (CoT)\n",
    "    \"\"\"\n",
    "\n",
    "    MCQ_ANSWER_EXTRACTION_PROMPT = 'The correct answer is ('\n",
    "\n",
    "    # Set up prompt for CoT case \n",
    "    prompt = format_prompt(query)\n",
    "\n",
    "    # Tokenize prompt\n",
    "    prompt_token_ids = tokenizer(\n",
    "        [prompt], \n",
    "        padding=True,\n",
    "        truncation=True, \n",
    "        max_length=8192,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(model.device)\n",
    "\n",
    "    # Generate model response based on input\n",
    "    # No sampling, just deterministic output to analyze faithfulness\n",
    "    with torch.inference_mode():\n",
    "        out_tok_ids = model.generate(\n",
    "            input_ids=prompt_token_ids['input_ids'], \n",
    "            attention_mask=prompt_token_ids['attention_mask'],\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=1000,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.95\n",
    "        )[0]\n",
    "\n",
    "    # Decode output tokens into English and parse output to remove question + options\n",
    "    output = tokenizer.decode(out_tok_ids.cpu(), skip_special_tokens=False)\n",
    "    output = \"\".join(output.split('[/INST]')[1:])\n",
    "    \n",
    "    # Tokenize answer extraction prompt for prompting model again for answer post CoT\n",
    "    answer_extraction_prompt = tokenizer(\n",
    "        MCQ_ANSWER_EXTRACTION_PROMPT, \n",
    "        truncation=True, \n",
    "        return_tensors='pt')['input_ids'].to(model.device)\n",
    "\n",
    "    if out_tok_ids[-1] == tokenizer.eos_token_id:\n",
    "        out_tok_ids = out_tok_ids[:-1]\n",
    "    out_tok_ids_w_answer_extraction = torch.concat([out_tok_ids, answer_extraction_prompt[0]])\n",
    "    out = model(out_tok_ids_w_answer_extraction.unsqueeze(0))\n",
    "\n",
    "    # Getting valid options from ASCII and converting to integer representation \n",
    "    options = query['options']\n",
    "    letters = list(string.ascii_uppercase)[:len(options)]\n",
    "    valid_option_ids = [tokenizer.convert_tokens_to_ids(o) for o in letters]\n",
    "\n",
    "    pred_idx = torch.argmax(out.logits[0, -1, valid_option_ids]).cpu()\n",
    "    pred = tokenizer.convert_ids_to_tokens(valid_option_ids[pred_idx])\n",
    "\n",
    "    return pred, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7a3b38-fc60-44e7-9257-3f8cef87455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"question\": \"In the coordinate plane, points (x, 1) and (5, y) are on line k. If line k passes through the origin and has slope 1/5, then what are the values of x and y respectively?\", \"options\": [\"A)4 and 1\", \"B)1 and 5\", \"C)5 and 1\", \"D)3 and 5\", \"E)5 and 3\"], \"rationale\": \"Line k passes through the origin and has slope 1/5 means that its equation is y=1/5*x.\\nThus: (x, 1)=(5, 1) and (5, y) = (5,1) -->x=5 and y=1\\nAnswer: C\", \"correct\": \"C\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "70752b0e-8ae1-4ac0-8a58-6acf2c180ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C',\n",
       " ' \\n\\n<think>\\nAlright, let\\'s try to tackle this problem step by step. So, we have two points on line k: (x, 1) and (5, y). The line k passes through the origin and has a slope of 1/5. We need to find the values of x and y from the given options.\\n\\nFirst, let me recall the equation of a line in slope-intercept form. It\\'s usually written as y = mx + b, where m is the slope and b is the y-intercept. However, since the line passes through the origin, the y-intercept b should be zero. So, the equation simplifies to y = mx.\\n\\nGiven the slope is 1/5, the equation of line k becomes y = (1/5)x. That seems straightforward.\\n\\nNow, since both points (x, 1) and (5, y) lie on this line, they must satisfy the equation y = (1/5)x.\\n\\nLet\\'s plug in the first point (x, 1). Substituting into the equation, we get:\\n1 = (1/5)x.\\n\\nHmm, solving for x, I can multiply both sides by 5:\\n5 * 1 = x\\nSo, x = 5.\\n\\nWait, that seems too straightforward. Let me check if I did that correctly. If x is 5, then plugging back into the equation, y should be (1/5)*5 = 1, which matches the given point (5, y). So, y would be 1. So, does that mean the point is (5,1)? But looking at the options, both C and A have 5 and 1. Hmm, but let me check the other point as well.\\n\\nWait, actually, the other point is (5, y). So, let\\'s plug x = 5 into the equation to find y:\\ny = (1/5)*5 = 1. So, y is indeed 1. So, the point (5, y) is (5,1). But the first point is (x, 1), so if x is 5, then the first point is also (5,1). That seems like both points are the same, which can\\'t be right because they are two distinct points on the line.\\n\\nWait, maybe I made a mistake here. Let me read the problem again: \"points (x, 1) and (5, y) are on line k.\" So, both points are on line k, but they are different points. So, if (x,1) and (5, y) are distinct, then x must not be 5. So, perhaps I messed up the substitution.\\n\\nWait, when I plugged in (x, 1), I got x = 5. So, that suggests that (x,1) is (5,1). But then, if (5,1) is one point, and (5,y) is another, then y must also be 1, which would make both points the same, which contradicts the fact that they are two different points. So, that suggests that maybe my initial substitution was incorrect.\\n\\nWait, no, maybe I need to consider both points together. Let me think. Since both points are on the line y = (1/5)x, so for (x,1), 1 = (1/5)x, so x = 5. For (5, y), y = (1/5)*5 = 1. So, both points are (5,1). That can\\'t be right because they are supposed to be two different points. So, perhaps the line isn\\'t y = (1/5)x? Wait, no, the slope is 1/5, and it passes through the origin, so y = (1/5)x is correct.\\n\\nWait, maybe the problem is that the points are (x,1) and (5,y), but if (x,1) is on the line, then x must be 5, but then (5,1) is the same as (5,y), so y must also be 1. So, both points are (5,1). That seems contradictory because they should be two different points. So, maybe I misread the problem.\\n\\nWait, let me check the problem again: \"points (x, 1) and (5, y) are on line k.\" So, line k passes through the origin and has slope 1/5. So, it\\'s y = (1/5)x.\\n\\nSo, if (x,1) is on the line, then 1 = (1/5)x, so x = 5. So, that point is (5,1). Similarly, if (5,y) is on the line,')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cot(model, tokenizer, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c0f9c-d35e-424c-8f47-1d43704053e6",
   "metadata": {},
   "source": [
    "What are we trying to achieve here?\n",
    "\n",
    "We have a model and a pretrained SAE for that model. We want to try and find reasoning-related components through the use of the SAE. What features reliably fire for questions that require reasoning, vs \"regular\" questions. What features fire when the CoT prompt is present vs absent? When we run faithfulness experiments, is there any feature that corresponds to hint verbalization? Is there a difference in feature activations between models that have the same answer prior to CoT and those that use the CoT to get to the answer?\n",
    "\n",
    "So first, let's try and find reasoning-related SAE features. To do that, we can try to find features that consistently activate strongly when the model is given questions that require reasoning, but don't activate when given other random input (e.g John went to the market today)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8907360a-096d-4e0e-bc82-a3bf0d8738b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqua_ds = load_dataset('aqua_rat', 'raw', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df4f50b-548f-4aeb-8262-c346fca5e058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'options', 'rationale', 'correct'],\n",
       "    num_rows: 254\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqua_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b4bdfb-6d60-4caf-a45b-5b231941a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sae_acts(text, layer, agg='mean'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**text, output_hidden_states=True, return_dict=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    raw_feats = sae.encode(hidden_states[layer])\n",
    "    if agg == 'mean':\n",
    "        return raw_feats[0].mean(axis=0) \n",
    "    elif agg == 'last':\n",
    "        return raw_feats[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68032939-a32f-467f-89b4-2a40f2f9158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_r = torch.zeros((aqua_ds.num_rows, sae.cfg.d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b2bd0f-eb31-4c9d-ab4d-2d74742671da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:23<00:00, 10.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, question in enumerate(tqdm(aqua_ds)):\n",
    "    prompt = format_prompt_aqua(question, reasoning=False)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    means_r[index, :] = get_sae_acts(inputs, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d856cd-a562-470b-97ea-b6d1f66bece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasts_r = torch.zeros((aqua_ds.num_rows, sae.cfg.d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a194b9-6012-42b4-a8e6-3f3bc147d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:23<00:00, 10.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, question in enumerate(tqdm(aqua_ds)):\n",
    "    prompt = format_prompt_aqua(question, reasoning=False)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    lasts_r[index, :] = get_sae_acts(inputs, 25, agg='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c63d8a-85c1-450b-9797-7af04d90f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ds = load_dataset(\"mandarjoshi/trivia_qa\", \"rc\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8971aaad-9920-4123-9da2-4b9dea6afd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_nr = torch.zeros((250, sae.cfg.d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2bc9ac4-2ab8-4935-81db-dcc88732f2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:19<00:00, 12.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, question in enumerate(tqdm(nr_ds[:250]['question'])):\n",
    "    prompt = format_prompt_tqa(question, reasoning=False)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    means_nr[index, :] = get_sae_acts(inputs, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0680bed8-a017-46f5-a2f5-772ba49f9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasts_nr = torch.zeros((250, sae.cfg.d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31aa5ee4-e2dd-49c5-a335-efb2ae662509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:19<00:00, 12.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, question in enumerate(tqdm(nr_ds[:250]['question'])):\n",
    "    prompt = format_prompt_tqa(question, reasoning=False)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    lasts_nr[index, :] = get_sae_acts(inputs, 25, agg='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b1f57806-187d-4b6d-9b8b-80e03f091458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_aqua = means_r.mean(axis=0)\n",
    "mean_aqua = trim_mean(means_r.detach(), proportiontocut=0.05, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6a440941-1836-48cf-bca0-f4d4daa505d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_trivia = means_nr.mean(axis=0) \n",
    "mean_trivia = trim_mean(means_nr.detach(), proportiontocut=0.05, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "80af5922-2c0f-461d-903b-7c06525d6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "percentage_increase = 100 * (mean_aqua - mean_trivia) / (mean_trivia + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b633bffe-222a-4e39-a257-c1dcf3d243f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = (mean_trivia > 0.01) & (mean_aqua > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8010cf91-319b-4b95-b5e8-b346064d0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_percentage_increase = percentage_increase[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1df3aa14-3e5d-4b18-97db-38741644fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = np.where(valid)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "41cdfb90-5cd3-4a34-8599-89edb914f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 16334: Aqua mean = 1.3904, Trivia mean = 0.0126, % increase = 10952.28%\n",
      "Feature 22315: Aqua mean = 0.4217, Trivia mean = 0.0142, % increase = 2864.22%\n",
      "Feature 9971: Aqua mean = 0.1110, Trivia mean = 0.0293, % increase = 278.54%\n",
      "Feature 5853: Aqua mean = 0.1697, Trivia mean = 0.0533, % increase = 218.07%\n",
      "Feature 4312: Aqua mean = 0.1986, Trivia mean = 0.0863, % increase = 130.04%\n",
      "Feature 6066: Aqua mean = 0.3660, Trivia mean = 0.1667, % increase = 119.53%\n",
      "Feature 4966: Aqua mean = 0.5258, Trivia mean = 0.3160, % increase = 66.37%\n",
      "Feature 31789: Aqua mean = 0.1309, Trivia mean = 0.1006, % increase = 30.07%\n",
      "Feature 12284: Aqua mean = 0.5369, Trivia mean = 0.4195, % increase = 27.98%\n",
      "Feature 31801: Aqua mean = 5.8519, Trivia mean = 5.2715, % increase = 11.01%\n"
     ]
    }
   ],
   "source": [
    "ranked_order = np.argsort(-filtered_percentage_increase)\n",
    "ranked_feature_indices = valid_indices[ranked_order] \n",
    "reasoning_feats = []\n",
    "\n",
    "top_k = 10\n",
    "for i in range(top_k):\n",
    "    idx = ranked_feature_indices[i]\n",
    "    reasoning_feats.append(idx)\n",
    "    print(f\"Feature {idx}: Aqua mean = {mean_aqua[idx]:.4f}, \"\n",
    "          f\"Trivia mean = {mean_trivia[idx]:.4f}, \"\n",
    "          f\"% increase = {percentage_increase[idx]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "794d9114-44b4-4a59-9d28-680135bae7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 16334: Aqua active = 92.1260, Trivia active = 19.2000\n",
      "Feature 22315: Aqua active = 95.6693, Trivia active = 20.8000\n",
      "Feature 9971: Aqua active = 79.9213, Trivia active = 31.2000\n",
      "Feature 5853: Aqua active = 94.4882, Trivia active = 43.2000\n",
      "Feature 4312: Aqua active = 93.3071, Trivia active = 57.6000\n",
      "Feature 6066: Aqua active = 99.2126, Trivia active = 80.8000\n",
      "Feature 4966: Aqua active = 99.6063, Trivia active = 97.6000\n",
      "Feature 31789: Aqua active = 100.0000, Trivia active = 100.0000\n",
      "Feature 12284: Aqua active = 100.0000, Trivia active = 100.0000\n",
      "Feature 31801: Aqua active = 100.0000, Trivia active = 100.0000\n"
     ]
    }
   ],
   "source": [
    "for feat in reasoning_feats:\n",
    "    print(f\"Feature {feat}: Aqua active = { 100 * (means_r[:, feat] > 0).sum() / 254:.4f}, Trivia active = {100 * (means_nr[:, feat] > 0).sum() / 250:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa78c-a6da-4a13-8871-195e7bedfc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
